{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fySlMD1iFevO",
        "outputId": "1b650e77-f413-41bb-bea9-23f2d2676adf"
      },
      "outputs": [],
      "source": [
        "import cv2  # Import open cv2 library\n",
        "import copy  # Import copy library\n",
        "import numpy as np  # Import numpy library\n",
        "import matplotlib.pyplot as plt  # Import matplotlib library\n",
        "from imutils import paths # Import imutils library\n",
        "from numpy.fft import fft2, ifft2 # Import fft and ifft modules\n",
        "from scipy.signal.windows import gaussian # import gaussian module\n",
        "from google.colab.patches import cv2_imshow #import cv2.im_show module\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "def scale(img,per):\n",
        "    scale_percent = per  # percent of original size\n",
        "    width = int(img.shape[1] * scale_percent / 100)  # scaling width of main image\n",
        "    height = int(img.shape[0] * scale_percent / 100)  # scaling height of main image\n",
        "    dim = (width, height) # dimensions of scaled image\n",
        "    img = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)  # resizing night image\n",
        "    return img\n",
        "\n",
        "\n",
        "def colored_equ(img):\n",
        "    b_n, g_n, r_n = cv2.split(img) # splitting the image in 3 (blue,green,red) channels\n",
        "    equ_b_nit = cv2.equalizeHist(b_n) # equalizing blue channel histogram\n",
        "    equ_g_nit = cv2.equalizeHist(g_n) # equalizing green channel histogram\n",
        "    equ_r_nit = cv2.equalizeHist(r_n) # equalizing red channel histogram\n",
        "    equalised = cv2.merge((equ_b_nit, equ_g_nit, equ_r_nit)) # merging three equalised histogram channels into one image\n",
        "    return equalised # returning of equalised colour image\n",
        "\n",
        "\n",
        "def gaussian_kernel(kernel_size): # gaussian function implementation for weiner filtering \n",
        "    h = gaussian(kernel_size, kernel_size / 3) #  giving arguments to gaussian funtion where kernel_size=n, kernel_size/3=sigma.\n",
        "    h = h.reshape(kernel_size, 1) # reshaping h matrix to (kernel_size,1) matrix\n",
        "    h = np.dot(h, h.transpose()) # matrix multiplication of h with h traanspose\n",
        "    h /= np.sum(h) # h=h/(sum of all elements of h matrix)\n",
        "    return h # returning h matrix\n",
        "\n",
        "\n",
        "def wiener_filter(img, kernel1, k):\n",
        "    kernel1 /= np.sum(kernel1) # kernel1=kernel1/(sum of all elements of kernel1 matrix)\n",
        "    dummy = np.copy(img) # making a copy of original image\n",
        "    dummy = np.fft.fft2(dummy) # computing fast fourier transform of given image\n",
        "    kernel1 = np.fft.fft2(kernel1,s=img.shape) # computing fast fourier transform of kernel1 \n",
        "    kernel1 = np.conj(kernel1) / (np.abs(kernel1) ** 2 + k) # according to formula given in slides for weiner filering\n",
        "    dummy = dummy * kernel1\n",
        "    dummy = np.abs(ifft2(dummy)) # inverse fourier transform of modified  image\n",
        "    return dummy # returning final output\n",
        "\n",
        "\n",
        "def contrast(grey):\n",
        "    mini = np.min(grey)  # computing minimum intesity  level of grey scale image\n",
        "    maxi = np.max(grey)  # computing maximum intesity  level of grey scale image\n",
        "    contrast_img = (int(maxi)-int(mini))/(int(maxi)+int(mini)) # computing contrast\n",
        "    return mini, maxi, float(contrast_img) # returning required values\n",
        "\n",
        "\n",
        "def variance_of_laplacian(image):\n",
        "    return cv2.Laplacian(image, cv2.CV_64F).var() # calculating laplacian of variance for quantification of bluriness\n",
        "\n",
        "\n",
        "def blur(gray):\n",
        "    fm = variance_of_laplacian(gray)  # calculates threshold value\n",
        "    text = \"Not Blurry\"\n",
        "    # if the focus measure is less than the supplied threshold,\n",
        "    # then the image should be considered \"blurry\"\n",
        "\n",
        "    if fm < 150:\n",
        "        text = \"Blurry\"\n",
        "    return fm,text\n",
        "\n",
        "\n",
        "def horizontal_notch_reject(shape): \n",
        "    p,q=shape # dimensions of image\n",
        "    H = np.zeros((p,q)) # zeros matrix\n",
        "    for u in range(0, p):\n",
        "        for v in range(0, q):\n",
        "            if p/2-p/100<=u<=p/2+p/100  and v<=q and np.sqrt((u - p/2) ** 2 + (v - q/2) ** 2) > 5: # drawing rectangular band reject filter  with circular gap at its center\n",
        "                H[u,v]=0\n",
        "            else:\n",
        "                H[u,v]=1\n",
        "    return H # returning band rejected matrix\n",
        "\n",
        "\n",
        "def notch_reject_filter(shape, d0=9, u_k=0, v_k=0): # drawing circular band reject around required point gives output in frquency domain as 0\n",
        "    P, Q = shape # dimensions of image\n",
        "    H = np.zeros((P, Q)) # zeros matrix\n",
        "    for u in range(0, P):\n",
        "        for v in range(0, Q):\n",
        "            D_uv = np.sqrt((u - P / 2 + u_k) ** 2 + (v - Q / 2 + v_k) ** 2) # condition for circle around a required point\n",
        "            D_muv = np.sqrt((u - P / 2 - u_k) ** 2 + (v - Q / 2 - v_k) ** 2)\n",
        "            if D_uv <= d0 or D_muv <= d0:\n",
        "                H[u, v] = 0.0 # output 0 for points lying inside the circle \n",
        "            else:\n",
        "                H[u, v] =1.0 # output 1 for points lying outside the circle\n",
        "    return H # returning band reject matrix\n",
        "\n",
        "\n",
        "\n",
        "def filtering(voyager): \n",
        "    f = np.fft.fft2(voyager) # calculating fourier transform of given image\n",
        "    fshift = np.fft.fftshift(f) # shifting frequency domain to center of plot \n",
        "    magnitude_spectrum = 20 * np.log(np.abs(fshift)) # magnitude spectrum of fft of image\n",
        "    notch_rej = fshift * horizontal_notch_reject(voyager.shape) # multiplying centered fft of image with notch reject filter in frequency domain\n",
        "    final = np.fft.ifftshift(notch_rej) # centralising inverse fourier transform of output image\n",
        "    final = np.fft.ifft2(final) # inverse fourier transform of output image\n",
        "    final = np.abs(final) # taking absolute value of final output\n",
        "    plt.imshow(magnitude_spectrum, cmap='gray') # magnitude spectrum of fft as output\n",
        "    plt.show()\n",
        "    plt.imshow(magnitude_spectrum * horizontal_notch_reject(voyager.shape), cmap='gray')  # modified  frequency domain plot after multiplicaion of two components\n",
        "    plt.show()\n",
        "    plt.imshow(final) # final image\n",
        "    plt.show()\n",
        "    return final\n",
        "\n",
        "\n",
        "def filtering1(dot_img):\n",
        "  f1 = np.fft.fft2(dot_img) # calculating fourier transform of given image\n",
        "  fshift1= np.fft.fftshift(f1) # shifting frequency domain to center of plot \n",
        "  magnitude_spectrum1 = 20*np.log(np.abs(fshift1)) # magnitude spectrum of fft of image\n",
        "  img_shape = dot_img.shape\n",
        "  H1 = notch_reject_filter(img_shape, 4, 58, 37) # circular dot centred at 58,37 points inside this circle goes to zero\n",
        "  H2 = notch_reject_filter(img_shape, 4, -52, 35) # circular dot centred at -52,35 points inside this circle goes to zero\n",
        "  H3 = notch_reject_filter(img_shape, 2, 80, 30) # circular dot centred at 80,32 points inside this circle goes to zero\n",
        "  H4 = notch_reject_filter(img_shape, 2, -82, 28) # circular dot centred at -82,28 points inside this circle goes to zero\n",
        "  NotchFilter = H1*H2*H3*H4 # multiplying all the notch filters in frequency domain\n",
        "  NotchRejectCenter = fshift1 * NotchFilter  # multiplying centered fft of image with notch reject filter in frequency domain\n",
        "  NotchReject = np.fft.ifftshift(NotchRejectCenter) # centralising inverse fourier transform of output image\n",
        "  inverse_NotchReject = np.fft.ifft2(NotchReject) # inverse fourier transform of output image\n",
        "  Result = np.abs(inverse_NotchReject) # taking absolute value of final output\n",
        "  plt.imshow(magnitude_spectrum1, cmap='gray') # magnitude spectrum of fft as output\n",
        "  plt.show()\n",
        "  plt.imshow(magnitude_spectrum1*NotchFilter, \"gray\")  # modified  frequency domain plot after multiplicaion of two components\n",
        "  plt.show()\n",
        "\n",
        "  return Result\n",
        "\n",
        "\n",
        "#  reading images\n",
        "nit_img = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/IMG_20220901_201400.jpg')\n",
        "dot_img = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/newspaper-dots.jpg')\n",
        "voyager = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/triton_voyager2.jpg')\n",
        "car = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/MakeNumberPlateReadable.jpg')\n",
        "dot_img = cv2.cvtColor(dot_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "# scaling images\n",
        "nit_img = scale(nit_img, 15)\n",
        "dot_img = scale(dot_img, 100)\n",
        "voyager = scale(voyager, 100)\n",
        "\n",
        "#  equalising images histogram\n",
        "equ_nit = colored_equ(nit_img)\n",
        "dot_img = cv2.equalizeHist(dot_img)\n",
        "\n",
        "\n",
        "#  de-noising images\n",
        "nit_noiseless = cv2.fastNlMeansDenoisingColored(equ_nit, None, 5, 5, 7, 21) # denoising using fastnl means denoising algorithm\n",
        "dot_noiseless = cv2.medianBlur(dot_img, 7) # median blurring of given image\n",
        "dot_noiseless = cv2.fastNlMeansDenoising(dot_noiseless, None, 15, 15, 21) # denoising using fastnl means denoising algorithm\n",
        "\n",
        "# removing Dots from newspaper 2nd method\n",
        "dot_dotless=filtering1(dot_img) # notch filtering of given image\n",
        "\n",
        "# voyager removing scan lines\n",
        "b_v, g_v, r_v = cv2.split(voyager) #spliting of image in three  channels\n",
        "b_v = filtering(b_v) # applying horizontal notch filter to blue channel seperately\n",
        "g_v = filtering(g_v) # applying horizontal notch filter to green channel seperately\n",
        "r_v = filtering(r_v) # applying horizontal notch filter to red channel seperately\n",
        "merged_voyager=cv2.merge((b_v,g_v,r_v)) # merging all channels into one\n",
        "\n",
        "#sharpening of image\n",
        "kernel1 = np.array([[0,-1,0], # sharpening matrix using laplacian filter\n",
        "                   [-1,5,-1],\n",
        "                   [0,-1,0]]) \n",
        "img_sharp = cv2.filter2D(car,ddepth=-1,kernel=kernel1)\n",
        "\n",
        "#  weiner filtering\n",
        "kernel = gaussian_kernel(3) # calculting gaussian values at each position\n",
        "b_c,g_c,r_c=cv2.split(car) #splitting images into three channels\n",
        "b_c = wiener_filter(b_c, kernel,0.5) # applying weiner filtering to blue channel\n",
        "g_c = wiener_filter(g_c, kernel,0.5) # applying weiner filtering to green channel\n",
        "r_c = wiener_filter(r_c, kernel,0.5) # applying weiner filtering to red channel\n",
        "merged_car=cv2.merge((b_c,g_c,r_c))  # merging all three channels into one\n",
        "\n",
        "'''plt.imshow(magnitude_spectrum, cmap='gray')\n",
        "plt.show()'''\n",
        "\n",
        "#   ML based restoring:\n",
        "\n",
        "\n",
        "#   Ml images reading\n",
        "bi1 = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/bad_pics/Screenshot_2022_0911_104252.png')\n",
        "bi2 = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/bad_pics/Screenshot_2022_0911_104215.png')\n",
        "bi3 = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/bad_pics/Screenshot_2022_0911_104142.png')\n",
        "bi4 = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/bad_pics/IMG_20220826_215838.jpg')\n",
        "bi5 = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/bad_pics/IMG_20220826_215842.png')\n",
        "bi6 = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/bad_pics/IMG_20220809_193235.jpg')\n",
        "bi7 = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/bad_pics/IMG_20220815_005116.jpg')\n",
        "bi8 = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/bad_pics/IMG_20220809_193235.jpg')\n",
        "gi1 = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/good_pics/training_set/IMG_20220831_214444.jpg')\n",
        "gi2 = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/good_pics/training_set/gandhi.jpg')\n",
        "gi3 = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/good_pics/training_set/IMG_20220815_022429.jpg')\n",
        "gi4 = cv2.imread('/content/drive/MyDrive/ee610_ass2_pics/good_pics/training_set/IMG_20220904_011934.jpg')\n",
        "#converting into gray scale images\n",
        "bi1 = cv2.cvtColor(bi1, cv2.COLOR_BGR2GRAY)\n",
        "bi2 = cv2.cvtColor(bi2, cv2.COLOR_BGR2GRAY)\n",
        "bi3 = cv2.cvtColor(bi3, cv2.COLOR_BGR2GRAY)\n",
        "bi4 = cv2.cvtColor(bi4, cv2.COLOR_BGR2GRAY)\n",
        "bi5 = cv2.cvtColor(bi5, cv2.COLOR_BGR2GRAY)\n",
        "bi6 = cv2.cvtColor(bi6, cv2.COLOR_BGR2GRAY)\n",
        "bi7 = cv2.cvtColor(bi7, cv2.COLOR_BGR2GRAY)\n",
        "bi8 = cv2.cvtColor(bi8, cv2.COLOR_BGR2GRAY)\n",
        "gi1 = cv2.cvtColor(gi1, cv2.COLOR_BGR2GRAY)\n",
        "gi2 = cv2.cvtColor(gi2, cv2.COLOR_BGR2GRAY)\n",
        "gi3 = cv2.cvtColor(gi3, cv2.COLOR_BGR2GRAY)\n",
        "gi4 = cv2.cvtColor(gi4, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#   scaling images\n",
        "bi1=scale(bi1,30)\n",
        "bi2=scale(bi2,30)\n",
        "bi3=scale(bi3,30)\n",
        "bi4=scale(bi4,30)\n",
        "bi5=scale(bi5,30)\n",
        "bi6=scale(bi6,30)\n",
        "bi7=scale(bi7,30)\n",
        "bi8=scale(bi8,30)\n",
        "\n",
        "gi1=scale(gi1,30)\n",
        "gi2=scale(gi2,30)\n",
        "gi3=scale(gi3,30)\n",
        "gi4=scale(gi4,30)\n",
        "#   Blurriness images checking:\n",
        "print('Variance value and blurriness of bad image 1 are : ',blur(bi1))\n",
        "print('Variance value and blurriness of bad image 2 are : ',blur(bi2))\n",
        "print('Variance value and blurriness of bad image 3 are : ',blur(bi3))\n",
        "print('Variance value and blurriness of bad image 4 are : ',blur(bi4))\n",
        "print('Variance value and blurriness of bad image 5 are : ',blur(bi5))\n",
        "print('Variance value and blurriness of bad image 6 are : ',blur(bi6))\n",
        "print('Variance value and blurriness of bad image 7 are : ',blur(bi7))\n",
        "print('Variance value and blurriness of bad image 8 are : ',blur(bi8))\n",
        "print('Variance value and blurriness of good image 1 are : ',blur(gi1))\n",
        "print('Variance value and blurriness of good image 2 are : ',blur(gi2))\n",
        "print('Variance value and blurriness of good image 3 are : ',blur(gi3))\n",
        "print('Variance value and blurriness of good image 4 are : ',blur(gi4))\n",
        "# average brightness\n",
        "print('average brightness of bad image 1 is : ', np.average(bi1))\n",
        "print('average brightness of bad image 2 is : ', np.average(bi2))\n",
        "print('average brightness of bad image 3 is : ', np.average(bi3))\n",
        "print('average brightness of bad image 4 is : ', np.average(bi4))\n",
        "print('average brightness of bad image 5 is : ', np.average(bi5))\n",
        "print('average brightness of bad image 6 is : ', np.average(bi6))\n",
        "print('average brightness of bad image 7 is : ', np.average(bi7))\n",
        "print('average brightness of bad image 8 is : ', np.average(bi8))\n",
        "print('average brightness of good image 1 is : ', np.average(gi1))\n",
        "print('average brightness of good image 2 is : ', np.average(gi2))\n",
        "print('average brightness of good image 3 is : ', np.average(gi3))\n",
        "print('average brightness of good image 4 is : ', np.average(gi4))\n",
        "#  contrast values checking of  bad and good images:\n",
        "print('Minimum , Maximum intensity level and contrast of 1st bad image:',contrast(bi1))\n",
        "print('Minimum , Maximum intensity level and contrast of 2nd bad image:',contrast(bi2))\n",
        "print('Minimum , Maximum intensity level and contrast of 3rd bad image:',contrast(bi3))\n",
        "print('Minimum , Maximum intensity level and contrast of 4th bad image:',contrast(bi4))\n",
        "print('Minimum , Maximum intensity level and contrast of 5th bad image:',contrast(bi5))\n",
        "print('Minimum , Maximum intensity level and contrast of 6th bad image:',contrast(bi6))\n",
        "print('Minimum , Maximum intensity level and contrast of 7th bad image:',contrast(bi7))\n",
        "print('Minimum , Maximum intensity level and contrast of 8th bad image:',contrast(bi8))\n",
        "print('Minimum , Maximum intensity level and contrast of 1st good image:',contrast(gi1))\n",
        "print('Minimum , Maximum intensity level and contrast of 2nd good image:',contrast(gi2))\n",
        "print('Minimum , Maximum intensity level and contrast of 3rd good image:',contrast(gi3))\n",
        "print('Minimum , Maximum intensity level and contrast of 4th good image:',contrast(gi4))\n",
        "#  tweaking good images to distort them by applying gaussian blur to all and then power transform for contrast changing :\n",
        "\n",
        "gci1 = copy.copy(gi1)\n",
        "gci2 = copy.copy(gi2)\n",
        "gci3 = copy.copy(gi3)\n",
        "gci4 = copy.copy(gi4)\n",
        "gci1 = cv2.GaussianBlur(gci1,(5,5),cv2.BORDER_DEFAULT)\n",
        "gci2 = cv2.GaussianBlur(gci2,(5,5),cv2.BORDER_DEFAULT)\n",
        "gci3 = cv2.GaussianBlur(gci3,(5,5),cv2.BORDER_DEFAULT)\n",
        "gci4 = cv2.GaussianBlur(gci4,(5,5),cv2.BORDER_DEFAULT)\n",
        "gci1 = np.array(255*((gci1/255)**0.4), dtype=np.uint8)\n",
        "gci2 = np.array(255*((gci2/255)**0.4), dtype=np.uint8)\n",
        "gci3 = np.array(255*((gci3/255)**0.4), dtype=np.uint8)\n",
        "gci4 = np.array(255*((gci4/255)**0.4), dtype=np.uint8)\n",
        "\n",
        "print('Variance value and blurriness of good distorted image 1 are : ',blur(gci1))\n",
        "print('Variance value and blurriness of good distorted image 2 are : ',blur(gci2))\n",
        "print('Variance value and blurriness of good distorted image 3 are : ',blur(gci3))\n",
        "print('Variance value and blurriness of good distorted image 4 are : ',blur(gci4))\n",
        "\n",
        "print('average brightness of good distorted image 1 is : ', np.average(gci1))\n",
        "print('average brightness of good distorted image 2 is : ', np.average(gci2))\n",
        "print('average brightness of good distorted image 3 is : ', np.average(gci3))\n",
        "print('average brightness of good distorted image 4 is : ', np.average(gci4))\n",
        "\n",
        "print('Minimum , Maximum intensity level and contrast of 1st good distorted image:',contrast(gci1))\n",
        "print('Minimum , Maximum intensity level and contrast of 2nd good distorted image:',contrast(gci2))\n",
        "print('Minimum , Maximum intensity level and contrast of 3rd good distorted image:',contrast(gci3))\n",
        "print('Minimum , Maximum intensity level and contrast of 4th good distorted image:',contrast(gci4))\n",
        "#  showing output\n",
        "cv2_imshow( nit_noiseless) # night noiseless image with increased brightness and  clarity\n",
        "cv2_imshow(dot_noiseless) # dot less image of newspaper man using median blurring\n",
        "cv2_imshow(img_sharp) # sharpened image of car \n",
        "cv2_imshow(merged_voyager) # horizontal notch filtered image of voyager\n",
        "cv2_imshow(merged_car) # weiner filtered image \n",
        "cv2_imshow(dot_dotless) # notch filtered dotless image\n",
        "#  Saving pic locally\n",
        "cv2.imwrite('nit noiseless.png', nit_noiseless, [cv2.IMWRITE_PNG_COMPRESSION])\n",
        "cv2.imwrite('dot noiseless.png', dot_noiseless, [cv2.IMWRITE_PNG_COMPRESSION])\n",
        "\n",
        "#  closing arguments\n",
        "cv2.waitKey(0)  # waiting till i close it\n",
        "cv2.destroyAllWindows()  # destroying all windows after stopping run\n",
        "\n",
        "''' sources:\n",
        "https://mathworld.wolfram.com/GaussianFunction.html\n",
        "https://docs.opencv.org/3.4/de/dbc/tutorial_py_fourier_transform.html\n",
        "https://stackoverflow.com/questions/65483030/notch-reject-filtering-in-python\n",
        "https://stackoverflow.com/questions/55288657/image-is-not-displaying-in-google-colab-while-using-imshow\n",
        "https://www.tutorialkart.com/opencv/python/opencv-python-gaussian-image-smoothing/#:~:text=Syntax%20%E2%80%93%20cv2%20GaussianBlur()%20function&text=%5Bheight%20width%5D.,is%20computed%20from%20sigma%20values.&text=Kernel%20standard%20deviation%20along%20X%2Daxis%20(horizontal%20direction).\n",
        "https://pyimagesearch.com/2015/09/07/blur-detection-with-opencv/\n",
        "https://www.analyticsvidhya.com/blog/2021/08/sharpening-an-image-using-opencv-library-in-python/\n",
        "https://www.bogotobogo.com/python/OpenCV_Python/python_opencv3_Image_Non-local_Means_Denoising_Algorithm_Noise_Reduction.php\n",
        "https://docs.opencv.org/3.4/d5/d69/tutorial_py_non_local_means.html\n",
        "\n",
        "'''\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}